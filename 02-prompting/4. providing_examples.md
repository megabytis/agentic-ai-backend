# Prompt Engineering Technique #3 **Providing Examples**

# **One-Shot & Multi-Shot Prompting**

## **ğŸ½ï¸ The Restaurant Analogy**

### **Situation:** Teaching a new chef how to cook your favorite dishes

**ğŸ˜• Zero-Shot Prompting** (give No Example)

> "Make me pasta."
> â†’ _Chef is confused. What kind? Sauce? Spicy? Vegetarian?_

**ğŸ¯ One-Shot Prompting** (give One Example)

> "Make me pasta **like this one**." (shows picture of carbonara)
> â†’ _Chef understands: creamy sauce, bacon, specific style_

**ğŸ“Š Multi-Shot Prompting** (give Multiple Examples)

> "Make me pasta **combining elements from these three**." (shows carbonara, bolognese, pesto)
> â†’ _Chef understands: variety of sauces, ingredients, presentation styles_

---

## **ğŸ“š Official Definitions**

### **One-Shot Prompting**

**Technical Definition:** Providing the LLM with **a single example** of the desired input-output pattern before asking it to perform the task.

**Simple Meaning:** "Here's ONE example of how to do it. Now you try."

### **Multi-Shot Prompting**

**Technical Definition:** Providing the LLM with **multiple examples** of the desired input-output patterns before asking it to perform the task.

**Simple Meaning:** "Here are SEVERAL examples showing different ways to do it. Now you try."

---

## **ğŸ”§ Core Technical Mechanism: Pattern Matching**

### **How LLMs Actually Learn from Examples:**

```
[EXAMPLE PATTERN LEARNED]
Input:  "Great service!"
Output: "positive"

[APPLIED TO NEW INPUT]
Input:  "Amazing experience!"
â†’ Model thinks: "This looks like 'Great service!' pattern"
â†’ Output: "positive"
```

**Key Insight:** LLMs don't "understand" - they **match patterns** from your examples.

---

## **ğŸ­ Real-World Example: Sentiment Analysis**

### **Problem:** LLM struggles with sarcasm

**Before Example:**

```
Tweet: "Yeah, I really needed my flight to be delayed. Perfect."
LLM Output: "positive" âŒ (Wrong!)
```

**After One-Shot Example:**

```
<example>
<input>"Fantastic, just what I needed - more work!"</input>
<output>negative</output>
</example>

Now analyze: "Yeah, I really needed my flight to be delayed. Perfect."
LLM Output: "negative" âœ… (Correct!)
```

---

## **ğŸ—ï¸ Advanced Use: Structured Output Formatting**

### **When You Need Specific JSON/XML Structure:**

```
<example>
<user_query>"Create a workout plan for muscle gain"</user_query>
<ideal_response>
{
  "workout_name": "Beginner Strength",
  "exercises": [
    {"name": "Squats", "sets": 3, "reps": 10},
    {"name": "Bench Press", "sets": 3, "reps": 8}
  ],
  "rest_days": ["Wednesday", "Sunday"]
}
</ideal_response>
</example>

Now generate workout for: "Create a cardio plan for weight loss"
```

**Result:** LLM copies the **exact JSON structure**, not just the content.

---

## **ğŸ® Practical Analogies for Different Scenarios**

### **1. Teaching Someone to Draw:**

- **Zero-shot:** "Draw a dog" ğŸ• â† Too vague
- **One-shot:** "Draw a dog **like this**" (shows one drawing) â† Clear style
- **Multi-shot:** Shows 3 different dog drawings (cartoon, realistic, abstract) â† Teaches range

### **2. Giving Directions:**

- **Zero-shot:** "Go to the bank" ğŸ¦ â† Which bank? Route?
- **One-shot:** "Go **this way**: Left at light, right at park" â† Clear path
- **Multi-shot:** Shows 3 different routes with landmarks â† Teaches alternatives

### **3. Writing Emails:**

- **Zero-shot:** "Write a professional email"
- **One-shot:** Shows one formal email template
- **Multi-shot:** Shows formal, casual, and urgent email styles

---

## **âš¡ When to Use Which (Decision Flowchart)**

```
                START: Need to prompt LLM
                        â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Is the task simple &        â”‚
          â”‚ formatting straightforward? â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
        YES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ NO
                        â†“ â†“
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ USE ONE-SHOTâ”‚    â”‚ USE MULTI-  â”‚
                â”‚             â”‚    â”‚ SHOT        â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â€¢ Quick tasks       â€¢ Complex tasks
                  â€¢ Clear patterns    â€¢ Multiple styles
                  â€¢ Low token cost    â€¢ Edge cases exist
```

---

## **ğŸ“ Implementation Examples**

### **One-Shot Example (Recipe Formatting):**

```
Format recipes like this example:

EXAMPLE RECIPE:
Title: Chocolate Chip Cookies
Prep Time: 15 minutes
Ingredients: 2 cups flour, 1 cup sugar
Steps: 1. Mix ingredients 2. Bake at 350Â°F

Now create recipe for: Banana Bread
```

### **Multi-Shot Example (Customer Support Responses):**

```
Respond to customer queries like these examples:

EXAMPLE 1 (Refund Request):
Customer: "I want my money back"
Response: "I understand you'd like a refund. Could you share your order number?"

EXAMPLE 2 (Technical Issue):
Customer: "App keeps crashing"
Response: "Sorry for the trouble. Which device and app version are you using?"

EXAMPLE 3 (General Inquiry):
Customer: "Do you ship internationally?"
Response: "Yes! We ship to 50+ countries. Where would you like it shipped?"

Now respond to: "My product arrived damaged"
```

---

## **ğŸš¨ Common Pitfalls & Solutions**

### **Pitfall 1: Examples Too Different**

âŒ Bad: Show email, tweet, and essay as examples for "write tweets"
âœ… Good: Show 3 different tweet styles

### **Pitfall 2: Not Labeling Examples**

âŒ Bad: Just dumping examples without structure
âœ… Good: Use `<example>`, `EXAMPLE 1:`, or clear numbering

### **Pitfall 3: Wrong Example Complexity**

âŒ Bad: Simple task with 5 complex examples
âœ… Good: Match example complexity to task complexity

---

## **ğŸ¯ Pro Tips from Practice**

### **1. The Goldilocks Principle:**

- **Too few examples:** LLM guesses
- **Too many examples:** Wastes tokens, can confuse
- **Just right:** 1-3 examples for most tasks

### **2. Example Quality > Quantity:**

One **perfect** example beats three mediocre ones.

### **3. Test Incrementally:**

Start with one-shot. If results are poor, add more examples.

### **4. Use Your Own Best Outputs:**

When you get a great response from the LLM, **save it as an example** for future use.

---

## **ğŸ“Š Token Economics**

```
One-Shot:     Base prompt + 1 example
Multi-Shot:   Base prompt + 2-3 examples

Rule: More examples = Better quality BUT Higher cost
```

**Budget tip:** For simple formatting, one-shot often suffices.

---

## **ğŸ”‘ Summary: The 3 Rules**

### **RULE 1:** LLMs are **pattern matchers**, not thinkers

They copy what you show them.

### **RULE 2:** **Show, don't just tell**

Examples teach better than descriptions.

### **RULE 3:** **Match examples to task complexity**

- Simple task â†’ One example
- Complex/varied task â†’ Multiple examples

---

## **ğŸ’¡ Final Mental Model**

Think of prompting as **teaching by demonstration**:

```
BEFORE: "Do it like this" (vague instruction)
AFTER:  "Watch me do it once, now you try" (clear demonstration)
```

**The magic happens when** the LLM sees your example and thinks: _"Oh, THAT'S what they want!"_
